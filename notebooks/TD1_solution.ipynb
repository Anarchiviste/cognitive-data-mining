{
 "cells": [
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "code",
   "source": [
    "####################################################################\n",
    "# This TD is using body data to explore :\n",
    "#  - Panda dataframe, import .dat, header, separator, change key names, save csv, sorting dataframe, replacing values, drop nan\n",
    "#  - Use of numpy : mean, median, max, min, var\n",
    "#  - plotting histogram, density function, bimodal\n",
    "#  - Confidence interval and boostrap computation, significance\n",
    "#  - Create and call python functions\n",
    "#  - Scatter plots, correlations, matrix of cross-correlation\n",
    "#  - Simpson paradox, bar plot\n",
    "\n"
   ],
   "id": "e0ac8c63d736c673",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "################# ################# #################\n",
    "################# Import packages\n",
    "################# ################# #################\n",
    "# If you are not familiar with Python : this part allow to import packages functions.\n",
    "# You can either import one function (from Package import Function) or the full package (import package as pkg) and call eah function of this package as pkg.function\n",
    "import pandas as pd              # Pandas : see https://pandas.pydata.org/docs/user_guide/10min.html\n",
    "import numpy as np               # Numpy : see https://numpy.org\n",
    "import matplotlib.pyplot as plt  # matplotlib for visualization : https://matplotlib.org\n",
    "import seaborn as sns            # seaborn is another plotting library : https://seaborn.pydata.org\n",
    "from random import choices\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ],
   "id": "969b4d7020115f65",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "################# ################# #################\n",
    "################# Open and format the data\n",
    "################# ################# #################\n",
    "    # -> Using pandas, you can open .dat or .csv data files\n",
    "dat =  pd.read_csv('./data_body/body.dat', sep='\\s+', header=None) # Open body.dat using read_csv function from pandas library.\n",
    "\n",
    "## Q1 ##  Using the same read_csv function from panda, open the description.csv file. Choose the correct 'sep' and 'header' parameters\n",
    "Description = pd.read_csv('./data_body/description.csv', sep=';', header=0) # Open description.csv with description and names of each variables\n",
    "dat = dat.rename(mapper=Description.loc[:,'Name'],axis=1) # Rename columns from dat with the name of the variable"
   ],
   "id": "36f3517ad6076dbd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "## Q2 ## save the dataframe as csv.\n",
    "dat.to_csv('./data_body/body.csv') # Save it to CSV so that we can look at it in excel."
   ],
   "id": "d198909194af7c7b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "################# ################# #################\n",
    "################# Look at mean and median, min, max...\n",
    "################# ################# #################\n",
    "dat['Weight'] # Print the Weight of all people\n",
    "## Q3 ## Using a function from numpy, compute the mean Weight\n",
    "mean_weight = np.mean(dat['Weight']) # Look at the average weight\n",
    "print(mean_weight)"
   ],
   "id": "ba2df532f7152f1f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "## Q4 ## Using a function from numpy, compute the median Weight\n",
    "median_weight = np.median(dat['Weight']) # Look at the median weight\n",
    "print(median_weight)"
   ],
   "id": "96fe77328fbd2dba",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "## Q5 ## Redo the same for the height\n",
    "mean_height = np.mean(dat['Height']) # Look at the average weight\n",
    "median_height = np.median(dat['Height']) # Look at the median weight\n",
    "print('mean_height:', mean_height, '  median_height:', median_height)"
   ],
   "id": "a3b94f7f57a1f0d9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "## Q6 ## Now select the column corresponding to biological sex of subjects\n",
    "dat['Sex'] # Print the sex of all people"
   ],
   "id": "b53685ceeb0d29a6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "## Q7 ## And look at its average value => What does it correspond to ? : XXXXXXXXXXXXXX\n",
    "np.mean(dat['Sex']) # Look at the average of sex => What does it correspond to ? = percentage of male in the dataset"
   ],
   "id": "41a9f3916ea15b2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "    # -> With numpy, you can alo find the Maximum / Minimum\n",
    "np.max(dat['Biacromial']) # Max Biacromial\n",
    "np.min(dat['Biacromial']) # Min Biacromial\n"
   ],
   "id": "55be17b813979037",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "################# ################# #################\n",
    "################# Sorting the data\n",
    "################# ################# #################\n",
    "    # -> Pandas dataframe can be sorted based of a given column. Find the correct method to apply on a dataframe to do so.\n",
    "## Q7 ## First sort the based on Biacromial value, ascending and plot those values. Plot another column of the dataframe.\n",
    "dat = dat.sort_values('Biacromial', ascending=True) # Sorting the data based on Biacromial value, ascending\n",
    "plt.plot(np.array(dat['Biacromial']))\n",
    "plt.show()"
   ],
   "id": "5f6a9a880ad33de9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "## Q8 ## And now base on the Biiliac, descending.\n",
    "dat = dat.sort_values('Biiliac', ascending=False) # Sorting the data based on Biliac value, descending\n",
    "    # ->  Note that all other columns, including the first one containing the index has been re-arranged to match the new order.\n",
    "print(dat)"
   ],
   "id": "d19bb5b9a33d530e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "################# ################# #################\n",
    "################# Look at the variability of the data\n",
    "################# ################# #################\n",
    "## Q9 ## Look at the doc from matplotlib.pyplot to plot the histogram of Weight with 100 bins.\n",
    "plt.hist(dat['Weight'], 100) # Look at the histogram of the Weight : what do you notice ?\n",
    "plt.show() # -> What do you notice ?"
   ],
   "id": "88869235db32342b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "## Q10 ## This command will find the outliers : 'dat['Weight']>200'. Use this to replace the outliers by nans in the dataframe\n",
    "dat.loc[dat['Weight']>200,'Weight'] = np.nan # Replace the two outliers with Nan"
   ],
   "id": "164efbc2a511fa50",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "dat['Weight']>200",
   "id": "486a84e94d03811d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "## Q11 ## Now replot the histogram and check that outliers are removed\n",
    "plt.hist(dat['Weight'], 100) # PLot the histogram now that the two outliers are removed\n",
    "plt.show()\n",
    "np.var(dat['Weight'])"
   ],
   "id": "b29fbd6d675dbf6e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "## Q12 ## Redo the same process with Height to plot the histogram without outliers\n",
    "plt.hist(dat['Height'], 100) # Look at the histogram of the Weight : what do you notice ?\n",
    "plt.show()\n",
    "dat.loc[dat['Height']>1000,'Height'] = np.nan # Replace the two outliers with Nan\n",
    "dat.loc[dat['Height']<50,'Height'] = np.nan # Replace the two outliers with Nan\n",
    "plt.hist(dat['Height'], 100) # Plot the histogram now that the two outliers are removed\n",
    "plt.show()\n",
    "np.var(dat['Height'])"
   ],
   "id": "9b32ba82b29738a7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "## Q13 ## barplot are interesting but if we want to see a continuous distribution, density plot are interesting. Find a use a function from seaborn package to compute density plot of the Weight/Height and age\n",
    "sns.kdeplot(dat['Weight'], bw_method=0.4) # Plot the kernel density plot with different kernel values\n",
    "plt.show()\n",
    "sns.kdeplot(dat['Height'], bw_method=0.4) # Plot the kernel density plot with different kernel values\n",
    "plt.show()\n",
    "sns.kdeplot(dat['Age'], bw_method=0.4) #Look at age distribution of this dataset\n",
    "plt.show()"
   ],
   "id": "2e9ba2c8fe8aa48b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "## Q14 ## Play with the kernel size and observe how ot changes the distribution plot.\n",
    "sns.kdeplot(dat['Weight'], bw_method=0.01) # Plot the kernel density plot with different kernel values\n",
    "plt.show()\n",
    "sns.kdeplot(dat['Weight'], bw_method=0.4) # Plot the kernel density plot with different kernel values\n",
    "plt.show()\n",
    "sns.kdeplot(dat['Weight'], bw_method=2) # Plot the kernel density plot with different kernel values\n",
    "plt.show()"
   ],
   "id": "e4263615d425958c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "## Q15 ## Plot the diameter of elbows with a kernel size of 1\n",
    "sns.kdeplot(dat['Elbow_diam'], bw_method=1)\n",
    "plt.show()"
   ],
   "id": "cf1ccd0019b385c2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "## Q16 ## Redo the same with a kernel size of 0.2 : What do you notice ?\n",
    "sns.kdeplot(dat['Elbow_diam'], bw_method=0.2) # Plot the kernel density plot of Elbow_diam with kernel value = 0.2 -> Bimodal\n",
    "plt.show()"
   ],
   "id": "5c965c131ae5a5f1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "## Q17 ## If you do not close the figure between two plots, they will overlapp. Use this to overlapp the density plt of elbow diameters of the whole population with the one with only males and the one with only females (alway with kernel width = 0.2). : What can you conclude ?\n",
    "sns.kdeplot(dat.loc[dat['Sex']==0,'Elbow_diam'], bw_method=0.2) # Now plot only form Men\n",
    "sns.kdeplot(dat.loc[dat['Sex']==1,'Elbow_diam'], bw_method=0.2) # And for Women -> We see where the bimodal distribution is coming from\n",
    "sns.kdeplot(dat['Elbow_diam'], bw_method=0.2) # Now plot only form Men\n",
    "plt.show()"
   ],
   "id": "7a02cb856f9dbae6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "## Q18 ## Now we will estimate the confidence interval of the weight using a boostrap method.\n",
    "# Now let's write a function that takes the name of the variable to consider, the index of subset of subject to consider, and the number of boostrap iteration and return the confidence interval of the mean\n",
    "# Estimate confidence interval of the average using boostrap method\n",
    "Weight =  np.array(dat['Weight'])\n",
    "np.mean(Weight)\n",
    "np.nanmean(Weight)\n",
    "n_suj = np.shape(Weight)[0]\n",
    "n_boostrap = 1000 # We will do 1000 boostrap iterations to estimate the mean\n",
    "allmeans = []\n",
    "for i in range(n_boostrap):\n",
    "    allmeans.append(np.nanmean(choices(Weight, k=n_suj)))\n",
    "print(allmeans)"
   ],
   "id": "704af827f6039626",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "## Q19 ## plot the density plot of all means\n",
    "sns.kdeplot(allmeans, bw_method=0.3) # PLot the distribution of estimated means\n",
    "plt.show()"
   ],
   "id": "6fd7036ed8eccfd6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "## Q20 ## Find the 2.5% lowest and 2.5% highest values of allmean :\n",
    "allmeans.sort() # Sort the list from low to high\n",
    "allmeans = allmeans[int(0.025*n_boostrap) : n_boostrap - int(0.025*n_boostrap) ] # remove 2.5% lowest and 2.5% highest values\n",
    "confidence_interval = [np.min(allmeans), np.max(allmeans)]\n",
    "    # Note that his three last line can be replaced by the following function : np.percentile(allmeans, [2.5, 97.5])\n",
    "print(confidence_interval)"
   ],
   "id": "1f72c3910b33dd15",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "## Q21 ## Now you will write a function that takes the name of the variable to consider, the index of subset of subject to consider, and the number of boostrap iteration and return the confidence interval of the mean\n",
    "def Mean_boostrapCI(name,subjects, n_boot):\n",
    "    var = np.array(dat.loc[subjects, name])\n",
    "    allmeans = []\n",
    "    for i in range(n_boot):\n",
    "        allmeans.append(np.nanmean(choices(var, k=np.shape(var)[0])))\n",
    "    confidence_interval = np.percentile(allmeans, [2.5, 97.5])\n",
    "    return (confidence_interval)\n"
   ],
   "id": "af1cd59880c49f39",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "## Q22 ## Use this function to compute the Weight CI male and female\n",
    "male  = dat['Sex']==1\n",
    "female  = dat['Sex']==0\n",
    "Male_CI = Mean_boostrapCI('Weight',male,  1000)\n",
    "Female_CI = Mean_boostrapCI('Weight',female,  1000)"
   ],
   "id": "19b83d1c088ddc98",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "## Q23 ## What can be concluded on the significance of mean Weight diff between male and female ? : \n",
    "print(Male_CI)\n",
    "print(Female_CI)"
   ],
   "id": "8bfdfc15c03b5960",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "## Q24 ## re-use the same function to compute the CI of the mean Height between people < 40 yo and people > 40 yo\n",
    "young  = dat['Age']<40\n",
    "old  = dat['Age']>40\n",
    "young_CI = Mean_boostrapCI('Height',young,  1000)\n",
    "old_CI = Mean_boostrapCI('Height',old,  1000)\n",
    "    # -> What can be concluded ?"
   ],
   "id": "8f0dbb83e1121c8b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "## Q25 ## What can you conclude ?\n",
    "print(young_CI)\n",
    "print(old_CI)"
   ],
   "id": "b8eb0f987b55c572",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "################# ################# #################\n",
    "################# Explore correlations between variables.\n",
    "################# ################# #################\n",
    "## Q26 ##  Using the scatter function from matplotlib.pyplot, show Height and Weight for each subject\n",
    "plt.scatter(dat['Weight'], dat['Elbow_diam']) # Scatter plot\n",
    "plt.show()"
   ],
   "id": "1dde252ff0d7c45c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "## Q27 ##  Compute the correlation between the two variables Height and Weight\n",
    "corr = dat['Weight'].corr(dat['Elbow_diam']) # With numpy corr = np.corcoef(dat.loc[:, 'Weight'],dat.loc[:, 'Height'], rowvar = False)\n",
    "print(corr)"
   ],
   "id": "b00c644dd76455de",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "## Q28 ## Redo the same for male and female separately\n",
    "plt.scatter(dat.loc[dat['Sex']==1, 'Weight'], dat.loc[dat['Sex']==1, 'Elbow_diam'])\n",
    "plt.scatter(dat.loc[dat['Sex']==0, 'Weight'], dat.loc[dat['Sex']==0, 'Elbow_diam'])\n",
    "plt.show()\n",
    "corr_maleonly = dat.loc[dat['Sex']==1, 'Weight'].corr(dat.loc[dat['Sex']==1, 'Elbow_diam'])\n",
    "corr_femaleonly = dat.loc[dat['Sex']==0, 'Weight'].corr(dat.loc[dat['Sex']==0, 'Elbow_diam'])\n",
    "    # -> The correlation coefficient reduced because part of the correlation was already explained by biological sex.\n",
    "print(corr_maleonly, corr_femaleonly)\n",
    "    "
   ],
   "id": "3976ac2b122a12fd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "## Q29 ## Write loops to look at the correlation of each pair of variable\n",
    "variables = dat.keys()\n",
    "n_var = np.shape(variables)[0]\n",
    "correlations = np.zeros([n_var,n_var])\n",
    "for i in range(n_var):\n",
    "    for j in range(n_var):\n",
    "        correlations[i, j] = dat[variables[i]].corr(dat[variables[j]])\n",
    "print(correlations)"
   ],
   "id": "e06807562e29557f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "## Q30 ## Plot the Matrix of correlations of all variables\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(correlations)\n",
    "plt.xticks(range(0,n_var))\n",
    "plt.yticks(range(0,n_var))\n",
    "ax.tick_params(axis='x', rotation=90)\n",
    "ax.set_xticklabels(variables)\n",
    "ax.set_yticklabels(variables)\n",
    "cbar = fig.colorbar(cax)\n",
    "plt.show()"
   ],
   "id": "1c63b1a006cc329f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "################# ################# #################\n",
    "################# The Simpson paradox\n",
    "################# ################# #################\n",
    "## Q31 ## Open the Data_vaccine.csv file and save it in .csv format\n",
    "vacc =  pd.read_csv('./data_vaccine/Data_vaccine.csv', sep=';', header=0) # Open the data file"
   ],
   "id": "98e5ff7dc7785f7f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "## Q32 ## Look at the mortality rate of vaccinated and non-vaccinated people\n",
    "with_vacc = np.mean(vacc.loc[vacc['Vaccine']==1, 'Deceased'])\n",
    "without_vacc = np.mean(vacc.loc[vacc['Vaccine']==0, 'Deceased'])\n",
    "plt.bar(['Vacc', 'noVacc'], [with_vacc,without_vacc], color=['g', 'b'])\n",
    "plt.show()\n",
    "    # -> What do you conclude ? Is the vaccine really dangerous ?"
   ],
   "id": "437bc72d0a11244a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "## Q33 ## Now, look at vaccination rate as a function of age\n",
    "vacc_rate_young = np.mean(vacc.loc[vacc['Age ']=='<60', 'Vaccine'])\n",
    "vacc_rate_old = np.mean(vacc.loc[vacc['Age ']=='>60', 'Vaccine'])\n",
    "print(vacc_rate_young, vacc_rate_old)"
   ],
   "id": "21f177783aa27fc7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "## Q34 ## And look at mortality rate as a function of age\n",
    "mortality_rate_young = np.mean(vacc.loc[vacc['Age ']=='<60', 'Deceased'])\n",
    "mortality_rate_old = np.mean(vacc.loc[vacc['Age ']=='>60', 'Deceased'])\n",
    "print(mortality_rate_young, mortality_rate_old)"
   ],
   "id": "c6c351c9f904cc2f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "## Q35 ## make a bar plot with mortality rate separated by vaccination status and age\n",
    "mortality_rate_young_vacc = np.mean(vacc.loc[(vacc['Vaccine']==1) & (vacc['Age ']=='<60'), 'Deceased'])\n",
    "mortality_rate_young_novacc = np.mean(vacc.loc[(vacc['Vaccine']==0) & (vacc['Age ']=='<60'), 'Deceased'])\n",
    "mortality_rate_old_vacc = np.mean(vacc.loc[(vacc['Vaccine']==1) & (vacc['Age ']=='>60'), 'Deceased'])\n",
    "mortality_rate_old_novacc = np.mean(vacc.loc[(vacc['Vaccine']==0) & (vacc['Age ']=='>60'), 'Deceased'])"
   ],
   "id": "4999d3d95fe7fb15",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.bar(['Young_Vacc', 'Young_noVacc','Old_Vacc', 'Old_noVacc'], [mortality_rate_young_vacc,mortality_rate_young_novacc,mortality_rate_old_vacc,mortality_rate_old_novacc ], color=['g', 'b','g', 'b'])\n",
    "plt.show()\n",
    "    # -> This is an example of a confounding factor creating the Simpson Paradox (https://fr.wikipedia.org/wiki/Paradoxe_de_Simpson)"
   ],
   "id": "4f0cfda8b9d4e62b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "d3a896c5fc4bbcce",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
