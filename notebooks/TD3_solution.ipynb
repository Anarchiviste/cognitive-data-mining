{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-05T09:04:24.854476Z",
     "start_time": "2025-03-05T09:04:24.485842Z"
    }
   },
   "cell_type": "code",
   "source": [
    "################# Install compatible versions of torch and torchtext\n",
    "!pip uninstall -y torch torchtext # uninstall previous verions to avoid conflits\n",
    "!pip install torch==2.0.1\n",
    "!pip install torchtext==0.15.2"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: pip\r\n",
      "zsh:1: command not found: pip\r\n",
      "zsh:1: command not found: pip\r\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-05T09:04:28.388578Z",
     "start_time": "2025-03-05T09:04:27.204947Z"
    }
   },
   "cell_type": "code",
   "source": [
    "################# ################# #################\n",
    "################# Import packages\n",
    "################# ################# #################\n",
    "import numpy as np\n",
    "import torchtext\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.manifold import MDS\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans"
   ],
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "dlopen(/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torchtext/lib/libtorchtext.so, 0x0006): Symbol not found: __ZN3c105ErrorC1ENSt3__112basic_stringIcNS1_11char_traitsIcEENS1_9allocatorIcEEEES7_PKv\n  Referenced from: <8349B302-A1C9-3870-AB5A-21A14A352BC2> /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torchtext/lib/libtorchtext.so\n  Expected in:     <BA9C42A5-EA1D-3784-80E1-73FBFDE05847> /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/lib/libc10.dylib",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mOSError\u001B[0m                                   Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[2], line 5\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m################# ################# #################\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;66;03m################# Import packages\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m################# ################# #################\u001B[39;00m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\n\u001B[0;32m----> 5\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorchtext\u001B[39;00m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpyplot\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mplt\u001B[39;00m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mseaborn\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01msns\u001B[39;00m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torchtext/__init__.py:18\u001B[0m\n\u001B[1;32m     15\u001B[0m     _WARN \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m     17\u001B[0m \u001B[38;5;66;03m# the following import has to happen first in order to load the torchtext C++ library\u001B[39;00m\n\u001B[0;32m---> 18\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorchtext\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m _extension  \u001B[38;5;66;03m# noqa: F401\u001B[39;00m\n\u001B[1;32m     20\u001B[0m _TEXT_BUCKET \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhttps://download.pytorch.org/models/text/\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     22\u001B[0m _CACHE_DIR \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mexpanduser(os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(_get_torch_home(), \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtext\u001B[39m\u001B[38;5;124m\"\u001B[39m))\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torchtext/_extension.py:64\u001B[0m\n\u001B[1;32m     59\u001B[0m     \u001B[38;5;66;03m# This import is for initializing the methods registered via PyBind11\u001B[39;00m\n\u001B[1;32m     60\u001B[0m     \u001B[38;5;66;03m# This has to happen after the base library is loaded\u001B[39;00m\n\u001B[1;32m     61\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorchtext\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m _torchtext  \u001B[38;5;66;03m# noqa\u001B[39;00m\n\u001B[0;32m---> 64\u001B[0m \u001B[43m_init_extension\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torchtext/_extension.py:58\u001B[0m, in \u001B[0;36m_init_extension\u001B[0;34m()\u001B[0m\n\u001B[1;32m     55\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m _mod_utils\u001B[38;5;241m.\u001B[39mis_module_available(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtorchtext._torchtext\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m     56\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtorchtext C++ Extension is not found.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m---> 58\u001B[0m \u001B[43m_load_lib\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mlibtorchtext\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     59\u001B[0m \u001B[38;5;66;03m# This import is for initializing the methods registered via PyBind11\u001B[39;00m\n\u001B[1;32m     60\u001B[0m \u001B[38;5;66;03m# This has to happen after the base library is loaded\u001B[39;00m\n\u001B[1;32m     61\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorchtext\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m _torchtext\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torchtext/_extension.py:50\u001B[0m, in \u001B[0;36m_load_lib\u001B[0;34m(lib)\u001B[0m\n\u001B[1;32m     48\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m path\u001B[38;5;241m.\u001B[39mexists():\n\u001B[1;32m     49\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[0;32m---> 50\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload_library\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     51\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/_ops.py:1350\u001B[0m, in \u001B[0;36m_Ops.load_library\u001B[0;34m(self, path)\u001B[0m\n\u001B[1;32m   1345\u001B[0m path \u001B[38;5;241m=\u001B[39m _utils_internal\u001B[38;5;241m.\u001B[39mresolve_library_path(path)\n\u001B[1;32m   1346\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m dl_open_guard():\n\u001B[1;32m   1347\u001B[0m     \u001B[38;5;66;03m# Import the shared library into the process, thus running its\u001B[39;00m\n\u001B[1;32m   1348\u001B[0m     \u001B[38;5;66;03m# static (global) initialization code in order to register custom\u001B[39;00m\n\u001B[1;32m   1349\u001B[0m     \u001B[38;5;66;03m# operators with the JIT.\u001B[39;00m\n\u001B[0;32m-> 1350\u001B[0m     \u001B[43mctypes\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mCDLL\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1351\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mloaded_libraries\u001B[38;5;241m.\u001B[39madd(path)\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/ctypes/__init__.py:374\u001B[0m, in \u001B[0;36mCDLL.__init__\u001B[0;34m(self, name, mode, handle, use_errno, use_last_error, winmode)\u001B[0m\n\u001B[1;32m    371\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_FuncPtr \u001B[38;5;241m=\u001B[39m _FuncPtr\n\u001B[1;32m    373\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m handle \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 374\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_handle \u001B[38;5;241m=\u001B[39m \u001B[43m_dlopen\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    375\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    376\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_handle \u001B[38;5;241m=\u001B[39m handle\n",
      "\u001B[0;31mOSError\u001B[0m: dlopen(/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torchtext/lib/libtorchtext.so, 0x0006): Symbol not found: __ZN3c105ErrorC1ENSt3__112basic_stringIcNS1_11char_traitsIcEENS1_9allocatorIcEEEES7_PKv\n  Referenced from: <8349B302-A1C9-3870-AB5A-21A14A352BC2> /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torchtext/lib/libtorchtext.so\n  Expected in:     <BA9C42A5-EA1D-3784-80E1-73FBFDE05847> /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/lib/libc10.dylib"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "################# ################# #################\n",
    "################# Download glove\n",
    "################# ################# #################\n",
    "glove = torchtext.vocab.GloVe(name=\"6B\", dim=100)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "A = glove['lamp']\n",
    "B = glove['candle']"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "################# ################# #################\n",
    "################# Word representation\n",
    "################# ################# #################\n",
    "# Look at the representation of the word 'lamp', 'candle', their euclidian distance and cosine similarity\n",
    "A = glove['lamp']\n",
    "B = glove['candle']\n",
    "euclidian  = np.sqrt(np.sum([(A[i]-B[i])**2 for i in range(np.shape(A)[0])])) # Using torch function euclidian = torch.norm(A - B)\n",
    "cosine = np.dot(A,B)/(np.linalg.norm(A)*np.linalg.norm(B)) # cosine = torch.cosine_similarity(A.unsqueeze(0), B.unsqueeze(0))\n",
    "print(euclidian, cosine)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Redo the same for mouse and lamp\n",
    "A = glove['lamp']\n",
    "B = glove['mouse']\n",
    "euclidian  = np.sqrt(np.sum([(A[i]-B[i])**2 for i in range(np.shape(A)[0])]))\n",
    "cosine = np.dot(A,B)/(np.linalg.norm(A)*np.linalg.norm(B))\n",
    "print(euclidian, cosine)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# using cosine similarity, find the 10 closest words to the word lamp\n",
    "A = glove['lamp']\n",
    "allwords = np.array(glove.itos)\n",
    "Similarity = []\n",
    "for word in allwords:\n",
    "    B = glove[word]\n",
    "    cosine = np.dot(A, B) / (np.linalg.norm(A) * np.linalg.norm(B))\n",
    "    Similarity.append(cosine)\n",
    "\n",
    "max_index = np.argsort(Similarity)[-10:-1]\n",
    "allwords[max_index]\n",
    "print(allwords[max_index])\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Write a function that takes as arg the embedding of a word and N and return the N closest words.\n",
    "def returnclosest(word, n):\n",
    "    allwords = np.array(glove.itos)\n",
    "    Similarity = []\n",
    "    for w in allwords:\n",
    "        other_word = glove[w]\n",
    "        cosine = np.dot(word, other_word) / (np.linalg.norm(word) * np.linalg.norm(other_word))\n",
    "        Similarity.append(cosine)\n",
    "\n",
    "    max_index = np.argsort(Similarity)[-(n+1):-1]\n",
    "    return(allwords[max_index])\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "close = returnclosest(glove['lamp'], 10)\n",
    "print(close)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "close = returnclosest(glove['rabbit'], 10)\n",
    "print(close)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "close = returnclosest(glove['bottle'], 10)\n",
    "print(close)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Now that words are vectors, we can move into that space. For example find the embedding of 'queen' - 'woman' + 'man'\n",
    "emb = glove['queen'] - glove['woman'] + glove['man']\n",
    "# Find the closest word to this new embeding\n",
    "returnclosest(emb, 1)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Check that the other realtion is true = 'king' - 'man' + 'woman' -> 'queen'\n",
    "returnclosest(glove['king'] - glove['man'] + glove['woman'], 1)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Now let's investigate biaises in glove embedings : look at the 3 closest words to : doctor - man + woman\n",
    "returnclosest(glove['doctor'] - glove['man'] + glove['woman'], 1)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "returnclosest(glove['doctor'] - glove['woman'] + glove['man'], 1)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "################# ################# #################\n",
    "################# Dimensionality reduction\n",
    "################# ################# #################\n",
    "###### Now let's consider the 20 following words = ['rabbit', 'mouse', 'horse', 'bear', 'chimpanzee','whale, 'dophin', 'parrot', 'sparrow', 'jay', 'sofa', 'table', 'chair', 'rug', 'lamp', 'computer, 'phone', 'keyborard', 'screen', 'plate']\n",
    "words = ['rabbit', 'mouse', 'horse', 'bear', 'monkey','whale', 'dolphin', 'tuna', 'swordfish', 'wolf', 'sofa', 'table', 'chair', 'rug', 'lamp','bag','computer', 'phone', 'keyboard', 'screen']\n",
    "sim = np.zeros([np.shape(words)[0],np.shape(words)[0]])\n",
    "for w1 in range(np.shape(words)[0]):\n",
    "    W1 = glove[words[w1]]\n",
    "    for w2 in range(np.shape(words)[0]):\n",
    "        W2 = glove[words[w2]]\n",
    "        sim[w1,w2] = np.dot(W1, W2) / (np.linalg.norm(W1) * np.linalg.norm(W2))\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "plt.matshow(sim)\n",
    "sim = pd.DataFrame(sim)\n",
    "sim = sim.rename(mapper=pd.Series(words),axis=1)\n",
    "ax = sns.clustermap(sim, cmap='coolwarm')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#perform multi-dimensional scaling\n",
    "mds = MDS(random_state=0)\n",
    "scaled_df = mds.fit_transform(sim)\n",
    "for i in range(np.shape(words)[0]):\n",
    "    plt.scatter(scaled_df[:,0][i], scaled_df[:,1][i])\n",
    "    plt.annotate(words[i], (scaled_df[:,0][i], scaled_df[:,1][i]))\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# perform PCA with one component\n",
    "pca = PCA(n_components=1)\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "X_reduced = pca.fit_transform(sim)\n",
    "for i in range(np.shape(words)[0]):\n",
    "    ax.scatter(X_reduced[:,0][i], 1)\n",
    "    ax.text(X_reduced[:, 0][i], 1, words[i], rotation = 35)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# perform PCA with two component\n",
    "pca = PCA(n_components=2)\n",
    "X_reduced = pca.fit_transform(sim)\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "for i in range(np.shape(words)[0]):\n",
    "    ax.scatter(X_reduced[:,0][i], X_reduced[:,1][i])\n",
    "    ax.text(X_reduced[:, 0][i], X_reduced[:, 1][i], words[i])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "# perform PCA with three component\n",
    "pca = PCA(n_components=3)\n",
    "X_reduced = pca.fit_transform(sim)\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "for i in range(np.shape(words)[0]):\n",
    "    ax.scatter(X_reduced[:,0][i], X_reduced[:,1][i], X_reduced[:,2][i])\n",
    "    ax.text(X_reduced[:,0][i], X_reduced[:,1][i], X_reduced[:,2][i],words[i])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Redo the sae with 800 first words.\n",
    "words = glove.itos[0:800]\n",
    "sim = np.zeros([np.shape(words)[0],np.shape(words)[0]])\n",
    "for w1 in range(np.shape(words)[0]):\n",
    "    W1 = glove[words[w1]]\n",
    "    for w2 in range(np.shape(words)[0]):\n",
    "        W2 = glove[words[w2]]\n",
    "        sim[w1,w2] = np.dot(W1, W2) / (np.linalg.norm(W1) * np.linalg.norm(W2))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "sim = pd.DataFrame(sim)\n",
    "sim = sim.rename(mapper=pd.Series(words),axis=1)\n",
    "ax = sns.clustermap(sim, cmap='coolwarm')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "pca = PCA(n_components=2)\n",
    "X_reduced = pca.fit_transform(sim)\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "for i in range(np.shape(words)[0]):\n",
    "    ax.scatter(X_reduced[:,0][i], X_reduced[:,1][i])\n",
    "    ax.text(X_reduced[:, 0][i], X_reduced[:, 1][i], words[i], fontsize = 'xx-small')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "pca = PCA(n_components=3)\n",
    "X_reduced = pca.fit_transform(sim)\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "for i in range(np.shape(words)[0]):\n",
    "    ax.scatter(X_reduced[:,0][i], X_reduced[:,1][i], X_reduced[:,2][i])\n",
    "    ax.text(X_reduced[:,0][i], X_reduced[:,1][i], X_reduced[:,2][i],words[i], fontsize = 'xx-small')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Kmeans on the similrity matrix and plot PCA colored with kmeans.\n",
    "kmeans = KMeans(n_clusters=6, random_state=0).fit(sim)\n",
    "kmeans.labels_\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "pca = PCA(n_components=2)\n",
    "X_reduced = pca.fit_transform(sim)\n",
    "colors = sns.color_palette(\"husl\", 6)\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "for i in range(np.shape(words)[0]):\n",
    "    ax.scatter(X_reduced[:,0][i], X_reduced[:,1][i], color=colors[kmeans.labels_[i]])\n",
    "    ax.text(X_reduced[:,0][i], X_reduced[:,1][i],words[i], fontsize = 'xx-small')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "pca = PCA(n_components=3)\n",
    "X_reduced = pca.fit_transform(sim)\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "for i in range(np.shape(words)[0]):\n",
    "    ax.scatter(X_reduced[:,0][i], X_reduced[:,1][i], X_reduced[:,2][i],color=colors[kmeans.labels_[i]])\n",
    "    ax.text(X_reduced[:,0][i], X_reduced[:,1][i], X_reduced[:,2][i],words[i], fontsize = 'xx-small')"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
